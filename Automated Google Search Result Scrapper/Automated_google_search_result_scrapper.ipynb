{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4) (2.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.27.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (2.2.3)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (0.27.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (2024.8.30)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (3.10)\n",
      "Requirement already satisfied: outcome in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.17.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.22)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver_manager in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from webdriver_manager) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from webdriver_manager) (1.0.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from webdriver_manager) (24.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->webdriver_manager) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->webdriver_manager) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->webdriver_manager) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->webdriver_manager) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_search_scraper(query, num_results=10):\n",
    "    search_url = f\"https://www.google.com/search?q={query}&num={num_results}\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\"}\n",
    "    \n",
    "    response = requests.get(search_url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Failed to fetch results\")\n",
    "        return\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    results = []\n",
    "\n",
    "    for g in soup.select('.tF2Cxc'):\n",
    "        title = g.select_one('h3').text if g.select_one('h3') else None\n",
    "        link = g.select_one('a')['href'] if g.select_one('a') else None\n",
    "        description = g.select_one('.VwiC3b').text if g.select_one('.VwiC3b') else None\n",
    "\n",
    "        if title and link:\n",
    "            results.append({\"Title\": title, \"Link\": link, \"Description\": description})\n",
    "\n",
    "    with open(\"google_search_results.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=[\"Title\", \"Link\", \"Description\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(results)\n",
    "\n",
    "    print(f\"Saved {len(results)} results to 'google_search_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 8 results to 'google_search_results.csv'\n"
     ]
    }
   ],
   "source": [
    "google_search_scraper(\"Python web scraping\", num_results=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_search_scraper_selenium(query, num_results=10, output_file=\"google_search_results.csv\"):\n",
    "    \"\"\"Scrapes Google search results for the given query and saves them to a CSV file.\"\"\"\n",
    "    \n",
    "    WAIT_TIME = 2\n",
    "    \n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")  \n",
    "    options.add_argument(\"--disable-gpu\")  \n",
    "    options.add_argument(\"--no-sandbox\")  \n",
    "    options.add_argument(\"--disable-dev-shm-usage\")  \n",
    "    service = Service(ChromeDriverManager().install())\n",
    "\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    print(\"Starting the browser and navigating to Google...\")\n",
    "\n",
    "    try:\n",
    "        driver.get(f\"https://www.google.com/search?q={query}&num={num_results}\")\n",
    "        time.sleep(WAIT_TIME)\n",
    "        print(\"Fetching search results...\")\n",
    "\n",
    "        # Scrape search results\n",
    "        results = []\n",
    "        search_results = driver.find_elements(By.CSS_SELECTOR, \".tF2Cxc\")\n",
    "\n",
    "        for result in search_results:\n",
    "            try:\n",
    "                title = result.find_element(By.CSS_SELECTOR, \"h3\").text\n",
    "\n",
    "                link = result.find_element(By.CSS_SELECTOR, \"a\").get_dom_attribute(\"href\")\n",
    "                \n",
    "                description_element = result.find_elements(By.CSS_SELECTOR, \".VwiC3b\")\n",
    "                description = description_element[0].text if description_element else \"No description available\"\n",
    "\n",
    "                if title and link:\n",
    "                    results.append({\"Title\": title, \"Link\": link, \"Description\": description})\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting a result: {e}\")\n",
    "                continue\n",
    "\n",
    "        with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "            writer = csv.DictWriter(file, fieldnames=[\"Title\", \"Link\", \"Description\"])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(results)\n",
    "\n",
    "        print(f\"Saved {len(results)} results to '{output_file}'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "        print(\"Browser closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the browser and navigating to Google...\n",
      "Fetching search results...\n",
      "Saved 8 results to 'google_search_results.csv'\n",
      "Browser closed.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    google_search_scraper_selenium(\"Python web scraping tutorial\", num_results=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Link</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Python Web Scraping Tutorial</td>\n",
       "      <td>https://www.geeksforgeeks.org/python-web-scrap...</td>\n",
       "      <td>11 Nov 2024 — In this tutorial, we'll explore ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python Web Scraping Tutorial: Step-By-Step [20...</td>\n",
       "      <td>https://oxylabs.io/blog/python-web-scraping</td>\n",
       "      <td>5 Mar 2024 — For this Python web scraping tuto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Practical Introduction to Web Scraping in Py...</td>\n",
       "      <td>https://realpython.com/python-web-scraping-pra...</td>\n",
       "      <td>In this tutorial, you'll learn all about web s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python Web Scraping: Full Tutorial With Exampl...</td>\n",
       "      <td>https://www.scrapingbee.com/blog/web-scraping-...</td>\n",
       "      <td>28 May 2024 — Learn about web scraping in Pyth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Python Web Scraping Tutorial</td>\n",
       "      <td>https://www.tutorialspoint.com/python_web_scra...</td>\n",
       "      <td>This tutorial will teach you various concepts ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Python Web Scraping Tutorial – How to Scrape D...</td>\n",
       "      <td>https://www.freecodecamp.org/news/how-to-scrap...</td>\n",
       "      <td>10 Aug 2021 — You will learn how to inspect a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Web Scraping Using Python</td>\n",
       "      <td>https://www.javatpoint.com/web-scraping-using-...</td>\n",
       "      <td>BeautifulSoup is a Python library that is used...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Web Scraping With Python – 2024 Full Guide</td>\n",
       "      <td>https://brightdata.com/blog/how-tos/web-scrapi...</td>\n",
       "      <td>Building a Web Scraper in Python · Step 1: Cho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                       Python Web Scraping Tutorial   \n",
       "1  Python Web Scraping Tutorial: Step-By-Step [20...   \n",
       "2  A Practical Introduction to Web Scraping in Py...   \n",
       "3  Python Web Scraping: Full Tutorial With Exampl...   \n",
       "4                       Python Web Scraping Tutorial   \n",
       "5  Python Web Scraping Tutorial – How to Scrape D...   \n",
       "6                          Web Scraping Using Python   \n",
       "7         Web Scraping With Python – 2024 Full Guide   \n",
       "\n",
       "                                                Link  \\\n",
       "0  https://www.geeksforgeeks.org/python-web-scrap...   \n",
       "1        https://oxylabs.io/blog/python-web-scraping   \n",
       "2  https://realpython.com/python-web-scraping-pra...   \n",
       "3  https://www.scrapingbee.com/blog/web-scraping-...   \n",
       "4  https://www.tutorialspoint.com/python_web_scra...   \n",
       "5  https://www.freecodecamp.org/news/how-to-scrap...   \n",
       "6  https://www.javatpoint.com/web-scraping-using-...   \n",
       "7  https://brightdata.com/blog/how-tos/web-scrapi...   \n",
       "\n",
       "                                         Description  \n",
       "0  11 Nov 2024 — In this tutorial, we'll explore ...  \n",
       "1  5 Mar 2024 — For this Python web scraping tuto...  \n",
       "2  In this tutorial, you'll learn all about web s...  \n",
       "3  28 May 2024 — Learn about web scraping in Pyth...  \n",
       "4  This tutorial will teach you various concepts ...  \n",
       "5  10 Aug 2021 — You will learn how to inspect a ...  \n",
       "6  BeautifulSoup is a Python library that is used...  \n",
       "7  Building a Web Scraper in Python · Step 1: Cho...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(pd.read_csv(\"google_search_results.csv\"))\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
